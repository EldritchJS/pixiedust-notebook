{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixiedust on Openshift/Daikon\n",
    "\n",
    "Start a pod via oc new-app pixiedust-notebook[-2.0.2].yaml\n",
    "Then browse to the route created as a result\n",
    "\n",
    "# Initial Pixiedust Import\n",
    "\n",
    "The first time pixiedust is imported within a Jupyter pyspark instance after installation (or pod instantiation) a kernel restart is requested. If requested, select Kernel--->Restart from the Jupyter menu bar above, making certain to run this cell again upon restart. If no restart is requested, run this cell and those after it without a restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (651, 72))\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "namedtuple() missing 3 required keyword-only arguments: 'verbose', 'rename', and 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-920006ea8d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpixiedust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#shortcut to logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpixiedust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdLogging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdLogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdLogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPixiedustLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mgetLogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdLogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/storage.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mre\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menviron\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixiedust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintEx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Attempt to enable urllib3's SNI support, if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyopenssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mpyopenssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_into_urllib3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/urllib3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from .connectionpool import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mHTTPConnectionPool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mHTTPSConnectionPool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from .exceptions import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mClosedPoolError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/urllib3/exceptions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from .packages.six.moves.http_client import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mIncompleteRead\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttplib_IncompleteRead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Base Exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/urllib3/packages/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mssl_match_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'ssl_match_hostname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/requests/packages/urllib3/packages/ssl_match_hostname/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fallback to vendored code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mssl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCertificateError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m DefaultVerifyPaths = namedtuple(\"DefaultVerifyPaths\",\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0;34m\"cafile capath openssl_cafile_env openssl_cafile openssl_capath_env \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \"openssl_capath\")\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jschless/.virtualenvs/testp3/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mnamedtuple\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_old_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_hack_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: namedtuple() missing 3 required keyword-only arguments: 'verbose', 'rename', and 'module'"
     ]
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "Pixiedust has a main import method, `pixiedust.sampleData()` in its API which returns a Spark DataFrame. In addition, it has a number of sample data sets to provide a quick start to data science using Pixiedust. Its visualization tools do not require using its data import tools, allowing legacy DataFrame code to remain intact.\n",
    "\n",
    "```python\n",
    "# Standard approaches\n",
    "sqlContext.createDataFrame(<Data values>)\n",
    "spark.read()\n",
    "# Additional Pixiedust approaches\n",
    "pixiedust.sampleData(<URL>)\n",
    "pixiedust.sampleData({1-7})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Package Install/Management\n",
    "Pixiedust advertises a means for installing Spark packages with lower overhead. Some things to note: the example code in some of the Pixiedust sample notebooks is flawed, as it omits a key step. The flow is as follows:\n",
    "1 Use pixiedust.installPackage({spark-package.org string, Maven repo info, URL to Jar}) to install the package/jar\n",
    "2 Restart the notebook kernel\n",
    "3 import pixiedust\n",
    "4 Use installPackage() to load the installed package\n",
    "Note: This has mixed results. For instance, the GraphFrames example Pixiedust uses does not function even after loading properly. The following example, however, does function (as of 12 June 2017 at least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package already installed: TargetHolding:pyspark-cassandra:0.3.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pixiedust.packageManager.package.Package at 0x1126c9128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixiedust.installPackage(\"TargetHolding:pyspark-cassandra:0.3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** For the initial call of the above, be sure to select Kernel--->Restart **AND** run the initial `import pixiedust` cell and the above cell again before proceeding to the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "julioasotodv:spark-df-profiling:1.1.2 => /Users/jschless/pixiedust/data/libs/spark-df-profiling-1.1.2.jar\n",
      "TargetHolding:pyspark-cassandra:0.3.5 => /Users/jschless/pixiedust/data/libs/pyspark-cassandra-0.3.5.jar\n"
     ]
    }
   ],
   "source": [
    "pixiedust.printAllPackages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "import pyspark_cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyspark_cassandra.conf' from '/private/var/folders/kk/lc4tj92149zfrd6ky3hrllfr0000gn/T/spark-9ca78303-0303-4d51-8ab6-e7f8d972c316/userFiles-75073fb0-5c74-4482-bb5e-2f155819b956/pyspark-cassandra-0.3.5.jar/pyspark_cassandra/conf.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_cassandra.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Job Monitor\n",
    "\n",
    "Pixiedust advertises a built-in spark job monitor for displaying job progress _in situ_ rather than tailing logfiles or otherwise. This is a neat feature, however, it's the only one which absolutely **does not** work beyond Spark 2.0. While the monitor can be enabled irrespective of version, beyond 2.0 an ugly error message will appear after a successfully enabled message(**sigh**), but otherwise the rest of the notebook should run fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully enabled Spark Job Progress Monitor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 47, in startSparkJobProgressMonitor\n",
      "    progressMonitor = SparkJobProgressMonitor()\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 174, in __init__\n",
      "    self.addSparkListener()\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/sparkJobProgressMonitor.py\", line 203, in addSparkListener\n",
      "    _env.getTemplate(\"sparkJobProgressMonitor/addSparkListener.scala\").render()\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2087, in run_cell_magic\n",
      "    result = fn(magic_arg_s, cell)\n",
      "  File \"<decorator-gen-124>\", line 2, in scala\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/scalaBridge.py\", line 179, in scala\n",
      "    runnerObject.callMethod(\"init\", pd_getJavaSparkContext(), None if self.hasLineOption(line, \"noSqlContext\") else self.interactiveVariables.getVar(\"sqlContext\")._ssql_ctx )\n",
      "  File \"/Users/jschless/.virtualenvs/testp3/lib/python3.6/site-packages/pixiedust/utils/javaBridge.py\", line 135, in callMethod\n",
      "    jMethodParams[i] = None if arg is None else (arg if arg.__class__.__name__ == \"JavaClass\" else arg.getClass())\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\", line 228, in __setitem__\n",
      "    return self.__set_item(key, value)\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\", line 211, in __set_item\n",
      "    return get_return_value(answer, self._gateway_client)\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 323, in get_return_value\n",
      "    format(target_id, \".\", name, value))\n",
      "py4j.protocol.Py4JError: An error occurred while calling None.None. Trace:\n",
      "java.lang.NullPointerException\n",
      "\tat py4j.commands.ArrayCommand.convertArgument(ArrayCommand.java:154)\n",
      "\tat py4j.commands.ArrayCommand.setArray(ArrayCommand.java:144)\n",
      "\tat py4j.commands.ArrayCommand.execute(ArrayCommand.java:97)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n",
      "\n",
      "\n",
      "\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1028, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 54] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/jschless/ViolinCases/GitHub/spark2.1/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    }
   ],
   "source": [
    "pixiedust.enableJobMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pixiedust.sampleData(\"https://github.com/ibm-cds-labs/open-data/raw/master/cars/cars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "\n",
    "This is where Pixiedust truly shines. Much like Tableau, Pixiedust takes a bunch of the heavy lifting out of exploratory data analyses by providing a means for trying out different visualizations on a DataFrame. Indeed, one need merely call `display(<DataFrame>)` and be on their way. No visualization lib imports, no advanced settings, just call and run with it.\n",
    "\n",
    "## Visualizing a Two-column DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tutorial paste: create a Spark dataframe, passing in some data, and assign it to a variable \n",
    "df = sqlContext.createDataFrame(\n",
    "[(\"Black\", 87),\n",
    " (\"Red\", 13)],\n",
    "[\"Colors\",\"%\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing an N-column DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Slightly modified Tutorial paste\n",
    "df2 = sqlContext.createDataFrame(\n",
    "[(2010, 'Air Hockey', 10),\n",
    " (2010, 'Curling', 20),\n",
    " (2010, 'Kendo', 1),\n",
    " (2010, 'Iaido', 2),\n",
    " (2010, 'Ninjitsu', 1),\n",
    " (2010, 'Ping Pong', 50),\n",
    " (2011, 'Air Hockey', 15),\n",
    " (2011, 'Curling', 30),\n",
    " (2011, 'Kendo', 5),\n",
    " (2011, 'Iaido', 10),\n",
    " (2011, 'Ninjitsu', 2),\n",
    " (2011, 'Ping Pong', 45),\n",
    " (2012, 'Air Hockey', 19),\n",
    " (2012, 'Curling', 34),\n",
    " (2012, 'Kendo', 6),\n",
    " (2012, 'Iaido', 11),\n",
    " (2012, 'Ninjitsu', 3),\n",
    " (2012, 'Ping Pong', 40)],\n",
    "[\"year\",\"sport\",\"unique_fans\"])\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sample Pixiedust data set to explore car data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Another tutorial paste, interesting cars data set\n",
    "df3 = pixiedust.sampleData(\"https://github.com/ibm-cds-labs/open-data/raw/master/cars/cars.csv\")\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sample Pixiedust data set to explore Boston crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "basemap": "dark-v9",
      "handlerId": "mapView",
      "keyFields": "X,Y",
      "kind": "simple",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA",
      "rendererId": "mapbox",
      "rowCount": "500",
      "valueFields": "type"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Not a tutorial paste, fun dataset\n",
    "bostonCrime = pixiedust.sampleData(7)\n",
    "display(bostonCrime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scala Bridge\n",
    "\n",
    "Pixiedust provides a means for sharing Python variables/data with Scala and Scala with Python. Scala code is entered after issueing the Pixiedust magic %%scala. \n",
    "\n",
    "## Python ---> Scala\n",
    "In the below example borrowed from a tutorial, Python variables are created then Scala is entered and the Python variables are printed. For Strings, they must be defined using double quotes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog=\"Weechee\"\n",
    "person=\"Jason\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%scala\n",
    "println(s\"$person has a dog named $dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala ---> Python\n",
    "\n",
    "In this example, a DataFrame is created within the Scala magic and the resulting DataFrame is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Slightly modified Tutorial paste\n",
    "//Reuse the sqlContext object available in the python scope\n",
    "val c = sqlContext.asInstanceOf[org.apache.spark.sql.SQLContext]\n",
    "import c.implicits._\n",
    "\n",
    "val __dfFromScala = Seq(\n",
    "    (2010, \"Air Hockey\", 10),\n",
    "    (2010, \"Curling\", 20),\n",
    "    (2010, \"Kendo\", 1),\n",
    "    (2010, \"Iaido\", 2),\n",
    "    (2010, \"Ninjitsu\", 1),\n",
    "    (2010, \"Ping Pong\", 50),\n",
    "    (2011, \"Air Hockey\", 15),\n",
    "    (2011, \"Curling\", 30),\n",
    "    (2011, \"Kendo\", 5),\n",
    "    (2011, \"Iaido\", 10),\n",
    "    (2011, \"Ninjitsu\", 2),\n",
    "    (2011, \"Ping Pong\", 45),\n",
    "    (2012, \"Air Hockey\", 19),\n",
    "    (2012, \"Curling\", 34),\n",
    "    (2012, \"Kendo\", 6),\n",
    "    (2012, \"Iaido\", 11),\n",
    "    (2012, \"Ninjitsu\", 3),\n",
    "    (2012, \"Ping Pong\", 40)).toDF(\"year\",\"sport\",\"unique_fans\")\n",
    "     \n",
    "__dfFromScala.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the DataFrame from Scala is converted to a Python DataFrame. Note: The Pixiedust tutorials do not include the conversion, however, it appears necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.common import _py2java, _java2py\n",
    "\n",
    "pythonDF = _java2py(sc, __dfFromScala)\n",
    "\n",
    "display(pythonDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.0)",
   "language": "python",
   "name": "pythonwithpixiedustspark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
